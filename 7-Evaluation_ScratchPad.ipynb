{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c912f0f7-4928-40a3-97ec-d9aeceb0d60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84636f1-302b-4225-a46d-d88f93f14c5a",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84365539-f917-44c4-929f-a7bd767a4bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import weave\n",
    "from weave import Evaluation\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee9ea19-75a6-45da-a93b-3489ca9cc5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect your examples\n",
    "examples = [\n",
    "    {\"question\": \"What is the capital of France?\", \"expected\": \"Paris\"},\n",
    "    {\"question\": \"Who wrote 'To Kill a Mockingbird'?\", \"expected\": \"Harper Lee\"},\n",
    "    {\"question\": \"What is the square root of 64?\", \"expected\": \"8\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57170ae0-c727-432e-abef-a9a09ba3e068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define any custom scoring function\n",
    "@weave.op()\n",
    "def match_score1(expected: str, model_output: dict) -> dict:\n",
    "    # Here is where you'd define the logic to score the model output\n",
    "    return {'match': expected == model_output['generated_text']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab1477d-2cf9-43f4-a3bf-aff45addc93a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "def function_to_evaluate(question: str):\n",
    "    # here's where you would add your LLM call and return the output\n",
    "    return  {'generated_text': 'Paris'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9b62980-4f77-484f-a03f-8cf2bb048957",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'model_output' key for compatibility with older scorers. Please update scorers to use 'output' parameter.\n"
     ]
    }
   ],
   "source": [
    "# Score your examples using scoring functions\n",
    "evaluation = Evaluation(\n",
    "    dataset=examples, scorers=[match_score1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e846df28-e1b8-4386-b1d0-8ecf045a36c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: paul-mriganka.\n",
      "View Weave data at https://wandb.ai/paul-mriganka-personal/scratchpad-example/weave\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'match_score1'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3333333333333333</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.005079587300618489</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'match_score1'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.3333333333333333\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.005079587300618489\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'match_score1': {'match': {'true_count': 1,\n",
       "   'true_fraction': 0.3333333333333333}},\n",
       " 'model_latency': {'mean': 0.005079587300618489}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/paul-mriganka-personal/scratchpad-example/r/call/019682d2-f888-7d70-856d-2b0651d80bc3\n"
     ]
    }
   ],
   "source": [
    "# Start tracking the evaluation\n",
    "weave.init('scratchpad-example')\n",
    "# Run the evaluation\n",
    "await evaluation.evaluate(function_to_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9f181-a2de-41db-93e4-feb8d7743312",
   "metadata": {},
   "source": [
    "### All in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "717472d5-cecb-46b3-a51c-cf929fee19f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'match_score1'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'match_score2'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.007790088653564453</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'match_score1'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'match_score2'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.007790088653564453\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'match_score1'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'match_score2'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.003944238026936849</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'match_score1'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'match_score2'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.003944238026936849\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'match_score1': {'match': {'true_count': 0, 'true_fraction': 0.0}},\n",
       " 'match_score2': {'match': {'true_count': 0, 'true_fraction': 0.0}},\n",
       " 'model_latency': {'mean': 0.003944238026936849}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weave import Evaluation, Model\n",
    "import weave\n",
    "import asyncio\n",
    "weave.init('intro-example')\n",
    "examples = [\n",
    "    {\"question\": \"What is the capital of France?\", \"expected\": \"Paris\"},\n",
    "    {\"question\": \"Who wrote 'To Kill a Mockingbird'?\", \"expected\": \"Harper Lee\"},\n",
    "    {\"question\": \"What is the square root of 64?\", \"expected\": \"8\"},\n",
    "]\n",
    "\n",
    "@weave.op()\n",
    "def match_score1(expected: str, model_output: dict) -> dict:\n",
    "    return {'match': expected == model_output['generated_text']}\n",
    "\n",
    "@weave.op()\n",
    "def match_score2(expected: dict, model_output: dict) -> dict:\n",
    "    return {'match': expected == model_output['generated_text']}\n",
    "\n",
    "class MyModel(Model):\n",
    "    prompt: str\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, question: str):\n",
    "        # here's where you would add your LLM call and return the output\n",
    "        return {'generated_text': 'Hello, ' + question + self.prompt}\n",
    "\n",
    "model = MyModel(prompt='World')\n",
    "evaluation = Evaluation(dataset=examples, scorers=[match_score1, match_score2])\n",
    "\n",
    "await evaluation.evaluate(model)\n",
    "\n",
    "@weave.op()\n",
    "def function_to_evaluate(question: str):\n",
    "    # here's where you would add your LLM call and return the output\n",
    "    return  {'generated_text': 'some response' + question}\n",
    "\n",
    "await evaluation.evaluate(function_to_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf297cc8-0de7-43cd-b5e0-bc3ec51c3411",
   "metadata": {},
   "source": [
    "### Preprocess model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbfc643b-0780-4f9c-8a53-668487edf757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'match_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.005599260330200195</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'match_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.005599260330200195\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'match_score': {'match': {'true_count': 0, 'true_fraction': 0.0}},\n",
       " 'model_latency': {'mean': 0.005599260330200195}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "from weave import Evaluation\n",
    "\n",
    "# Our dataset has \"input_text\" but our model expects \"question\"\n",
    "examples = [\n",
    "    {\"input_text\": \"What is the capital of France?\", \"expected\": \"Paris\"},\n",
    "    {\"input_text\": \"Who wrote 'To Kill a Mockingbird'?\", \"expected\": \"Harper Lee\"},\n",
    "    {\"input_text\": \"What is the square root of 64?\", \"expected\": \"8\"},\n",
    "]\n",
    "\n",
    "@weave.op()\n",
    "def preprocess_example(example):\n",
    "    # Rename input_text to question\n",
    "    return {\n",
    "        \"question\": example[\"input_text\"]\n",
    "    }\n",
    "\n",
    "@weave.op()\n",
    "def match_score(expected: str, model_output: dict) -> dict:\n",
    "    return {'match': expected == model_output['generated_text']}\n",
    "\n",
    "@weave.op()\n",
    "def function_to_evaluate(question: str):\n",
    "    return {'generated_text': f'Answer to: {question}'}\n",
    "\n",
    "# Create evaluation with preprocessing\n",
    "evaluation = Evaluation(\n",
    "    dataset=examples,\n",
    "    scorers=[match_score],\n",
    "    preprocess_model_input=preprocess_example\n",
    ")\n",
    "\n",
    "# Run the evaluation\n",
    "weave.init('preprocessing-example')\n",
    "await evaluation.evaluate(function_to_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ea4fc-a58c-4586-8ccd-525040f4c564",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6129ec78-d92e-4f7b-9741-65970115e52a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: paul-mriganka.\n",
      "View Weave data at https://wandb.ai/paul-mriganka-personal/intro-example/weave\n",
      "üì¶ Published to https://wandb.ai/paul-mriganka-personal/intro-example/weave/objects/grammar/versions/ozZFHzO1w2hjwzUPPwdacGRwC9YH9Q6TgstzGbRiK44\n",
      "üç© https://wandb.ai/paul-mriganka-personal/intro-example/r/call/019682e5-7657-7e22-83c2-3a766b30e3b0\n"
     ]
    }
   ],
   "source": [
    "import weave\n",
    "from weave import Dataset\n",
    "# Initialize Weave\n",
    "weave.init('intro-example')\n",
    "\n",
    "# Create a dataset\n",
    "dataset = Dataset(\n",
    "    name='grammar',\n",
    "    rows=[\n",
    "        {'id': '0', 'sentence': \"He no likes ice cream.\", 'correction': \"He doesn't like ice cream.\"},\n",
    "        {'id': '1', 'sentence': \"She goed to the store.\", 'correction': \"She went to the store.\"},\n",
    "        {'id': '2', 'sentence': \"They plays video games all day.\", 'correction': \"They play video games all day.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Publish the dataset\n",
    "weave.publish(dataset)\n",
    "\n",
    "# Retrieve the dataset\n",
    "dataset_ref = weave.ref('grammar').get()\n",
    "\n",
    "# Access a specific example\n",
    "example_label = dataset_ref.rows[2]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d82dea7-477b-4134-91e6-f24afc30ed4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They plays video games all day.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afbc5382-2037-435f-8a29-0ad7a5e693cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/paul-mriganka-personal/intro-example/r/call/019682e5-765c-7902-9bf0-08409af8915c\n"
     ]
    }
   ],
   "source": [
    "@weave.op\n",
    "def model(task: str) -> str:\n",
    "    return f\"Now working on {task}\"\n",
    "\n",
    "res1, call1 = model.call(task=\"fetch\")\n",
    "res2, call2 = model.call(task=\"parse\")\n",
    "\n",
    "dataset = Dataset.from_calls([call1, call2])\n",
    "# Now you can use the dataset to evaluate the model, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3052d-c111-4970-a1d5-2217b5e5e84a",
   "metadata": {},
   "source": [
    "### Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03820558-5eba-441d-8947-8280801d66ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e366f781-79b1-4383-b167-57539cda7ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    {'id': '0', 'sentence': \"He no likes ice cream.\", 'correction': \"He doesn't like ice cream.\"},\n",
    "    {'id': '1', 'sentence': \"She goed to the store.\", 'correction': \"She went to the store.\"},\n",
    "    {'id': '2', 'sentence': \"They plays video games all day.\", 'correction': \"They play video games all day.\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcfd347e-4fda-4f3a-852d-80149604bf04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40b2f5b5-a87c-4ebc-9e7a-31f8bcff0521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "541a256f-4a47-4cb4-b466-7da4bd55956d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert df.equals(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121c402-d14f-47c9-b5f9-d511691f5b21",
   "metadata": {},
   "source": [
    "### Function based scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd35c06c-cbc8-435f-b5b8-0239b23100f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(name=None, description=None, dataset=Dataset(name=None, description=None, rows=<weave.trace.table.Table object at 0x7f4f40265240>), scorers=[<function evaluate_uppercase at 0x7f4f400ca170>], preprocess_model_input=None, trials=1, evaluation_name=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "\n",
    "@weave.op\n",
    "def evaluate_uppercase(text: str) -> dict:\n",
    "    return {\"text_is_uppercase\": text.isupper()}\n",
    "\n",
    "evaluation = weave.Evaluation(\n",
    "    dataset=[{\"text\": \"HELLO WORLD\"}],\n",
    "    scorers=[evaluate_uppercase]\n",
    ")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b5c7d-bf44-4a2e-9f56-8c28257853b8",
   "metadata": {},
   "source": [
    "### Class based scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b133f79-0634-4474-89c6-d2742449caf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import weave\n",
    "from openai import OpenAI\n",
    "from weave import Scorer\n",
    "\n",
    "llm_client = OpenAI()\n",
    "\n",
    "class SummarizationScorer(Scorer):\n",
    "    model_id: str = \"gpt-4o\"\n",
    "    system_prompt: str = \"Evaluate whether the summary is good.\"\n",
    "\n",
    "    @weave.op\n",
    "    def some_complicated_preprocessing(self, text: str) -> str:\n",
    "        processed_text = \"Original text: \\n\" + text + \"\\n\"\n",
    "        return processed_text\n",
    "\n",
    "    @weave.op\n",
    "    def call_llm(self, summary: str, processed_text: str) -> dict:\n",
    "        res = llm_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": (\n",
    "                    f\"Analyse how good the summary is compared to the original text.\"\n",
    "                    f\"Summary: {summary}\\n{processed_text}\"\n",
    "                )}])\n",
    "        return {\"summary_quality\": res}\n",
    "\n",
    "    @weave.op\n",
    "    def score(self, output: str, text: str) -> dict:\n",
    "        \"\"\"Score the summary quality.\n",
    "\n",
    "        Args:\n",
    "            output: The summary generated by an AI system\n",
    "            text: The original text being summarized\n",
    "        \"\"\"\n",
    "        processed_text = self.some_complicated_preprocessing(text)\n",
    "        eval_result = self.call_llm(summary=output, processed_text=processed_text)\n",
    "        return {\"summary_quality\": eval_result}\n",
    "\n",
    "evaluation = weave.Evaluation(\n",
    "    dataset=[{\"text\": \"The quick brown fox jumps over the lazy dog.\"}],\n",
    "    scorers=[SummarizationScorer()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8d937dc-4295-4cc9-a0c0-e6c50312921f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(name=None, description=None, dataset=Dataset(name=None, description=None, rows=<weave.trace.table.Table object at 0x7f4f400fc6d0>), scorers=[SummarizationScorer(name=None, description=None, column_map=None, model_id='gpt-4o', system_prompt='Evaluate whether the summary is good.')], preprocess_model_input=None, trials=1, evaluation_name=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ac3dd-7fe6-4aa6-b9cc-ed9d4a6dd5d1",
   "metadata": {},
   "source": [
    "### Built-in scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd955480-98c9-4ccd-aa3a-46b1437917eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86b7a46e-e21d-495b-aac6-571a42abe0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting code deps for <function HallucinationFreeScorer.score at 0x7f4f400e0550>: unmatched ')' (<unknown>, line 141)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'HallucinationFreeScorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'has_hallucination'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.011968851089477539</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'HallucinationFreeScorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'has_hallucination'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.011968851089477539\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HallucinationFreeScorer': {'has_hallucination': {'true_count': 2, 'true_fraction': 1.0}}, 'model_latency': {'mean': 0.011968851089477539}}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import weave\n",
    "from weave.scorers import HallucinationFreeScorer\n",
    "\n",
    "# Initialize scorer with a column mapping if needed.\n",
    "hallucination_scorer = HallucinationFreeScorer(\n",
    "    model_id=\"openai/gpt-4o\", # or any other model supported by litellm\n",
    "    column_map={\"context\": \"input\", \"output\": \"other_col\"}\n",
    ")\n",
    "\n",
    "# Create dataset\n",
    "dataset = [\n",
    "    {\"input\": \"John likes various types of cheese.\"},\n",
    "    {\"input\": \"Pepe likes various types of cheese.\"},\n",
    "]\n",
    "\n",
    "@weave.op\n",
    "def model(input: str) -> str:\n",
    "    return \"The person's favorite cheese is cheddar.\"\n",
    "\n",
    "# Run evaluation\n",
    "evaluation = weave.Evaluation(\n",
    "    dataset=dataset,\n",
    "    scorers=[hallucination_scorer],\n",
    ")\n",
    "print(await evaluation.evaluate(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f37962-7962-492d-a296-fa4154910946",
   "metadata": {},
   "source": [
    "### Summarization Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab1eae57-6efe-414e-beee-8d8a4e2a7d50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting code deps for <function SummarizationScorer._evaluate_summary at 0x7f4f400e32e0>: unmatched ')' (<unknown>, line 141)\n",
      "Error getting code deps for <function SummarizationScorer._extract_entities at 0x7f4f400e3250>: unmatched ')' (<unknown>, line 141)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'SummarizationScorer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'is_entity_dense'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'entity_density'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'summarization_eval_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0007735490798950195</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'SummarizationScorer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'is_entity_dense'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'entity_density'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'summarization_eval_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.0007735490798950195\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'SummarizationScorer': {'is_entity_dense': {'true_count': 0,\n",
       "   'true_fraction': 0.0},\n",
       "  'entity_density': {'mean': 0.0},\n",
       "  'summarization_eval_score': {'mean': 0.0}},\n",
       " 'model_latency': {'mean': 0.0007735490798950195}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import weave\n",
    "from weave.scorers import SummarizationScorer\n",
    "\n",
    "class SummarizationModel(weave.Model):\n",
    "    @weave.op()\n",
    "    async def predict(self, input: str) -> str:\n",
    "        return \"This is a summary of the input text.\"\n",
    "\n",
    "# Initialize scorer\n",
    "summarization_scorer = SummarizationScorer(\n",
    "    model_id=\"openai/gpt-4o\"  # or any other model supported by litellm\n",
    ")\n",
    "# Create dataset\n",
    "dataset = [\n",
    "    {\"input\": \"The quick brown fox jumps over the lazy dog.\"},\n",
    "    {\"input\": \"Artificial Intelligence is revolutionizing various industries.\"}\n",
    "]\n",
    "# Run evaluation\n",
    "evaluation = weave.Evaluation(dataset=dataset, scorers=[summarization_scorer])\n",
    "await evaluation.evaluate(SummarizationModel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf8ccb4-2f40-46b4-ab4d-8e6aa4d0bedb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### OpenAIModerationScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5bf9701-0d81-42e5-bef7-0a93bbe823bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'OpenAIModerationScorer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'categories'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'violence'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'passed'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00043952465057373047</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'OpenAIModerationScorer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'categories'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'violence'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'passed'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.00043952465057373047\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OpenAIModerationScorer': {'categories': {'violence': {'true_count': 1, 'true_fraction': 1.0}}, 'passed': {'true_count': 1, 'true_fraction': 0.5}}, 'model_latency': {'mean': 0.00043952465057373047}}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import weave\n",
    "from weave.scorers import OpenAIModerationScorer\n",
    "\n",
    "class MyModel(weave.Model):\n",
    "    @weave.op\n",
    "    async def predict(self, input: str) -> str:\n",
    "        return input\n",
    "\n",
    "# Initialize scorer\n",
    "moderation_scorer = OpenAIModerationScorer()\n",
    "\n",
    "# Create dataset\n",
    "dataset = [\n",
    "    {\"input\": \"I love puppies and kittens!\"},\n",
    "    {\"input\": \"I hate everyone and want to hurt them.\"}\n",
    "]\n",
    "\n",
    "# Run evaluation\n",
    "evaluation = weave.Evaluation(dataset=dataset, scorers=[moderation_scorer])\n",
    "print(await evaluation.evaluate(MyModel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc456a-08c7-4cbb-9b19-3e106b4ce3b1",
   "metadata": {},
   "source": [
    "### EmbeddingSimilarityScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7521a468-52d1-45d5-9211-e4795aa1edb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'EmbeddingSimilarityScorer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'similarity_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8449273654072489</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'is_similar'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0044291019439697266</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'EmbeddingSimilarityScorer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'similarity_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.8449273654072489\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'is_similar'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.0044291019439697266\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EmbeddingSimilarityScorer': {'similarity_score': {'mean': 0.8449273654072489}, 'is_similar': {'true_count': 1, 'true_fraction': 0.5}}, 'model_latency': {'mean': 0.0044291019439697266}}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import weave\n",
    "from weave.scorers import EmbeddingSimilarityScorer\n",
    "\n",
    "# Initialize scorer\n",
    "similarity_scorer = EmbeddingSimilarityScorer(\n",
    "    model_id=\"openai/text-embedding-3-small\",  # or any other model supported by litellm\n",
    "    threshold=0.7\n",
    ")\n",
    "# Create dataset\n",
    "dataset = [\n",
    "    {\n",
    "        \"input\": \"He's name is John\",\n",
    "        \"target\": \"John likes various types of cheese.\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"He's name is Pepe.\",\n",
    "        \"target\": \"Pepe likes various types of cheese.\",\n",
    "    },\n",
    "]\n",
    "# Define model\n",
    "@weave.op\n",
    "def model(input: str) -> str:\n",
    "    return \"John likes various types of cheese.\"\n",
    "\n",
    "# Run evaluation\n",
    "evaluation = weave.Evaluation(\n",
    "    dataset=dataset,\n",
    "    scorers=[similarity_scorer],\n",
    ")\n",
    "print(await evaluation.evaluate(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe5f41-a51e-4876-97c9-de22e338fbaf",
   "metadata": {},
   "source": [
    "### ValidJSONScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1580a564-17f6-471a-be8d-8ed434f5ac03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ValidJSONScorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'json_valid'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0007185935974121094</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'ValidJSONScorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'json_valid'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.0007185935974121094\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ValidJSONScorer': {'json_valid': {'true_count': 2, 'true_fraction': 1.0}}, 'model_latency': {'mean': 0.0007185935974121094}}\n"
     ]
    }
   ],
   "source": [
    "import weave\n",
    "from weave.scorers import ValidJSONScorer\n",
    "\n",
    "class JSONModel(weave.Model):\n",
    "    @weave.op()\n",
    "    async def predict(self, input: str) -> str:\n",
    "        # This is a placeholder.\n",
    "        # In a real scenario, this would generate JSON.\n",
    "        return '{\"key\": \"value\"}'\n",
    "\n",
    "model = JSONModel()\n",
    "json_scorer = ValidJSONScorer()\n",
    "\n",
    "dataset = [\n",
    "    {\"input\": \"Generate a JSON object with a key and value\"},\n",
    "    {\"input\": \"Create an invalid JSON\"}\n",
    "]\n",
    "\n",
    "evaluation = weave.Evaluation(dataset=dataset, scorers=[json_scorer])\n",
    "print(await evaluation.evaluate(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d72c9c-7b74-4fed-b83f-99d13844414a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ValidXMLScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa312f0b-88b8-4277-9e52-d5398d2f3ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ValidXMLScorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'xml_valid'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0003446340560913086</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'ValidXMLScorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'xml_valid'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.0003446340560913086\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ValidXMLScorer': {'xml_valid': {'true_count': 2, 'true_fraction': 1.0}}, 'model_latency': {'mean': 0.0003446340560913086}}\n"
     ]
    }
   ],
   "source": [
    "import weave\n",
    "from weave.scorers import ValidXMLScorer\n",
    "\n",
    "class XMLModel(weave.Model):\n",
    "    @weave.op()\n",
    "    async def predict(self, input: str) -> str:\n",
    "        # This is a placeholder. In a real scenario, this would generate XML.\n",
    "        return '<root><element>value</element></root>'\n",
    "\n",
    "model = XMLModel()\n",
    "xml_scorer = ValidXMLScorer()\n",
    "\n",
    "dataset = [\n",
    "    {\"input\": \"Generate a valid XML with a root element\"},\n",
    "    {\"input\": \"Create an invalid XML\"}\n",
    "]\n",
    "\n",
    "evaluation = weave.Evaluation(dataset=dataset, scorers=[xml_scorer])\n",
    "print(await evaluation.evaluate(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e41a41d-5826-4f50-87f4-d7489f7747c9",
   "metadata": {},
   "source": [
    "### RAGAS Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "231405c8-f633-4438-b3c7-ada78ad884b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from weave.scorers import ContextRelevancyScorer\n",
    "\n",
    "relevancy_scorer = ContextRelevancyScorer(\n",
    "    model_id=\"openai/gpt-4o\",  # or any other model supported by litellm\n",
    "    relevancy_prompt=\"\"\"\n",
    "Given the following question and context, rate the relevancy of the context to the question on a scale from 0 to 1.\n",
    "\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Relevancy Score (0-1):\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc72fd1f-fe27-40f5-bd4c-ed1b413b1104",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting code deps for <function ContextRelevancyScorer.score at 0x7f4f400e2830>: unmatched ')' (<unknown>, line 141)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m2\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ContextEntityRecallScorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ContextRelevancyScorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'relevancy_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00036144256591796875</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'ContextEntityRecallScorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'recall'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'ContextRelevancyScorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'relevancy_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.00036144256591796875\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ContextEntityRecallScorer': {'recall': {'mean': 0.5}}, 'ContextRelevancyScorer': {'relevancy_score': {'mean': 0.5}}, 'model_latency': {'mean': 0.00036144256591796875}}\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "import weave\n",
    "from weave.scorers import ContextEntityRecallScorer, ContextRelevancyScorer\n",
    "\n",
    "class RAGModel(weave.Model):\n",
    "    @weave.op()\n",
    "    async def predict(self, question: str) -> str:\n",
    "        \"Retrieve relevant context\"\n",
    "        return \"Paris is the capital of France.\"\n",
    "\n",
    "# Define prompts\n",
    "relevancy_prompt: str = dedent(\"\"\"\n",
    "    Given the following question and context, rate the relevancy of the context to the question on a scale from 0 to 1.\n",
    "\n",
    "    Question: {question}\n",
    "    Context: {context}\n",
    "    Relevancy Score (0-1):\n",
    "    \"\"\")\n",
    "# Initialize scorers\n",
    "entity_recall_scorer = ContextEntityRecallScorer()\n",
    "relevancy_scorer = ContextRelevancyScorer(relevancy_prompt=relevancy_prompt)\n",
    "# Create dataset\n",
    "dataset = [\n",
    "    {\n",
    "        \"question\": \"What is the capital of France?\",\n",
    "        \"context\": \"Paris is the capital city of France.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who wrote Romeo and Juliet?\",\n",
    "        \"context\": \"William Shakespeare wrote many famous plays.\"\n",
    "    }\n",
    "]\n",
    "# Run evaluation\n",
    "evaluation = weave.Evaluation(\n",
    "    dataset=dataset,\n",
    "    scorers=[entity_recall_scorer, relevancy_scorer]\n",
    ")\n",
    "print(await evaluation.evaluate(RAGModel()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c4dee-88f4-4380-979d-c14a87dc82e4",
   "metadata": {},
   "source": [
    "### Switching to other providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4477d030-4124-4847-b477-ad42c5e8ba1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from weave.scorers import SummarizationScorer\n",
    "\n",
    "# Switch to Anthropic's Claude model\n",
    "summarization_scorer = SummarizationScorer(\n",
    "    model_id=\"anthropic/claude-3-5-sonnet-20240620\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762de23a-dcaa-4192-95a7-f1858d99810f",
   "metadata": {},
   "source": [
    "## Weave local scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ca75658-0804-48f2-bd3b-553137a09cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cu124)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /opt/conda/lib/python3.10/site-packages (from torch) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /opt/conda/lib/python3.10/site-packages (from torch) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /opt/conda/lib/python3.10/site-packages (from torch) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Installing collected packages: safetensors, transformers\n",
      "Successfully installed safetensors-0.5.3 transformers-4.51.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9c66457a-b8cf-477e-96d6-050bd242af02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact bias_scorer:v0, 551.93MB. 28 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   28 of 28 files downloaded.  \n",
      "Done. 0:0:5.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is biased: True\n",
      "passed=False metadata={'gender_bias_score': 0.604306161403656, 'gender_bias': True, 'racial_bias_score': 0.34831076860427856, 'racial_bias': False}\n"
     ]
    }
   ],
   "source": [
    "import weave\n",
    "from weave.scorers import WeaveBiasScorerV1\n",
    "\n",
    "bias_scorer = WeaveBiasScorerV1()\n",
    "result = bias_scorer.score(output=\"Martian men are terrible at cleaning\")\n",
    "\n",
    "print(f\"The text is biased: {not result.passed}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b5563-db17-4b72-ae0a-b0a848b21e6a",
   "metadata": {},
   "source": [
    "##### And more...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53b886-3382-4d9a-a75c-4df6e5bbd637",
   "metadata": {},
   "source": [
    "### Evaluation Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ec739da-67c2-4780-a895-02e6ad47ccaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: paul-mriganka.\n",
      "View Weave data at https://wandb.ai/paul-mriganka-personal/logger-example-project/weave\n",
      "üç© https://wandb.ai/paul-mriganka-personal/logger-example-project/r/call/01968389-7e1f-7e43-b700-53f910bbac90\n",
      "Evaluation logging complete. View results in the Weave UI.\n",
      "üç© https://wandb.ai/paul-mriganka-personal/logger-example-project/r/call/0196838d-e451-76e1-a20b-fdd31a50714e\n",
      "üç© https://wandb.ai/paul-mriganka-personal/logger-example-project/r/call/01968390-06d1-72d3-9a97-fd9ad0714b80\n"
     ]
    }
   ],
   "source": [
    "import weave\n",
    "from openai import OpenAI\n",
    "from weave.flow.eval_imperative import EvaluationLogger\n",
    "\n",
    "weave.init(\"logger-example-project\")\n",
    "\n",
    "# Initialize the logger (model/dataset names are optional metadata)\n",
    "eval_logger = EvaluationLogger(\n",
    "    model=\"my_model\",\n",
    "    dataset=\"my_dataset\"\n",
    ")\n",
    "\n",
    "# Example input data (this can be any data structure you want)\n",
    "eval_samples = [\n",
    "    {'inputs': {'a': 1, 'b': 2}, 'expected': 3},\n",
    "    {'inputs': {'a': 2, 'b': 3}, 'expected': 5},\n",
    "    {'inputs': {'a': 3, 'b': 4}, 'expected': 7},\n",
    "]\n",
    "\n",
    "# Example model logic.  This does not have to be decorated with @weave.op,\n",
    "# but if you do, it will be traced and logged.\n",
    "@weave.op\n",
    "def user_model(a: int, b: int) -> int:\n",
    "    oai = OpenAI()\n",
    "    _ = oai.chat.completions.create(messages=[{\"role\": \"user\", \"content\": f\"What is {a}+{b}?\"}], model=\"gpt-4o-mini\")\n",
    "    return a + b\n",
    "\n",
    "# Iterate through examples, predict, and log\n",
    "for sample in eval_samples:\n",
    "    inputs = sample[\"inputs\"]\n",
    "    model_output = user_model(**inputs) # Pass inputs as kwargs\n",
    "\n",
    "    # Log the prediction input and output\n",
    "    pred_logger = eval_logger.log_prediction(\n",
    "        inputs=inputs,\n",
    "        output=model_output\n",
    "    )\n",
    "\n",
    "    # Calculate and log a score for this prediction\n",
    "    expected = sample[\"expected\"]\n",
    "    correctness_score = model_output == expected\n",
    "    pred_logger.log_score(\n",
    "        scorer=\"correctness\", # Simple string name for the scorer\n",
    "        score=correctness_score\n",
    "    )\n",
    "\n",
    "    # Finish logging for this specific prediction\n",
    "    pred_logger.finish()\n",
    "\n",
    "# Log a final summary for the entire evaluation.\n",
    "# Weave auto-aggregates the 'correctness' scores logged above.\n",
    "summary_stats = {\"subjective_overall_score\": 0.8}\n",
    "eval_logger.log_summary(summary_stats)\n",
    "\n",
    "print(\"Evaluation logging complete. View results in the Weave UI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5fdbd5-d5cc-49a0-b702-63946c189c7d",
   "metadata": {},
   "source": [
    "### Log Rich media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7d3f30b-e2d5-4ea1-bf84-d3056483de8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import wave\n",
    "import struct\n",
    "from PIL import Image\n",
    "import random\n",
    "from typing import Any\n",
    "import weave\n",
    "\n",
    "def generate_random_audio_wave_read(duration=2, sample_rate=44100):\n",
    "    n_samples = duration * sample_rate\n",
    "    amplitude = 32767  # 16-bit max amplitude\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "\n",
    "    # Write wave data to the buffer\n",
    "    with wave.open(buffer, 'wb') as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)  # 16-bit\n",
    "        wf.setframerate(sample_rate)\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            sample = random.randint(-amplitude, amplitude)\n",
    "            wf.writeframes(struct.pack('<h', sample))\n",
    "\n",
    "    # Rewind the buffer to the beginning so we can read from it\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Return a Wave_read object\n",
    "    return wave.open(buffer, 'rb')\n",
    "\n",
    "rich_media_dataset = [\n",
    "    {\n",
    "        'image': Image.new(\n",
    "            \"RGB\",\n",
    "            (100, 100),\n",
    "            color=(\n",
    "                random.randint(0, 255),\n",
    "                random.randint(0, 255),\n",
    "                random.randint(0, 255),\n",
    "            ),\n",
    "        ),\n",
    "        \"audio\": generate_random_audio_wave_read(),\n",
    "    }\n",
    "    for _ in range(5)\n",
    "]\n",
    "\n",
    "@weave.op\n",
    "def your_output_generator(image: Image.Image, audio) -> dict[str, Any]:\n",
    "    return {\n",
    "        \"result\": random.randint(0, 10),\n",
    "        \"image\": image,\n",
    "        \"audio\": audio,\n",
    "    }\n",
    "\n",
    "ev = EvaluationLogger(model=\"example_model\", dataset=\"example_dataset\")\n",
    "\n",
    "for inputs in rich_media_dataset:\n",
    "    output = your_output_generator(**inputs)\n",
    "    pred = ev.log_prediction(inputs, output)\n",
    "    pred.log_score(scorer=\"greater_than_5_scorer\", score=output[\"result\"] > 5)\n",
    "    pred.log_score(scorer=\"greater_than_7_scorer\", score=output[\"result\"] > 7)\n",
    "\n",
    "ev.log_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94943af-0276-48e3-9300-e7fdff6a8292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-4.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/pytorch-gpu.2-4:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
